Dear Editors and Reviewers,

Thank you very much for the constructive and insightful comments provided on our manuscript entitled "Reliable Clinical Decision-making Driven by Large Language Models: Framework and Application." We have carefully considered all the feedback and made significant revisions to address each point comprehensively. Below is a detailed summary of our responses and actions taken:

### Reviewer 2

1. **Lack of implementation details:**

   - **Knowledge Engineering:** Clarified in the Methods (Medical Dataset section), detailing knowledge acquisition, management, and organization processes.
   - **Agent Architecture:** Expanded description in Methods (Decision Methodology section), including comparison to mainstream frameworks and highlighting MedRad's lightweight, self-developed features.
   - **LLM Fine-tuning:** Added detailed information in Appendix 1 (AiMed training specifics), describing model selection, parameters, and optimization strategies.
2. **Detailed implementation and evaluation metrics:**

   - Implementation details of each component (RAG, CoT, Agent) added in Methods and Appendices 3 & 4.
   - Algorithms detailed with pseudocode provided in Appendices 3 & 4.
   - Dataset clearly described, including National Medical Qualification Exam dataset (quantitative) and 200 anonymized clinical records from collaborating hospitals (qualitative) in Results.
   - Evaluation metrics (accuracy, recall, F1 scores, and qualitative clinical evaluations) thoroughly explained in Results and further detailed in Appendix 5.
3. **Consistency and quality of figures:**

   - Figures redrawn and standardized with 300 dpi resolution.
4. **Additional relevant literature:**

   - Added the suggested citation and discussion regarding medical legal implications of AI (Shifaa, 2025) in the Related Work section.
5. **Potential future directions:**

   - Expanded the Discussion section, exploring future applications in multilingual environments, broader medical scenarios, and integration with other medical AI systems.

### Reviewer 3

1. **Substantial innovation and reproducibility:**

   - Provided detailed methodology and technical specifications to reinforce reproducibility and clarify MedRad's innovative aspects in Methods and Appendices.
2. **Detailed evaluation scenarios and metrics:**

   - Comprehensive details added in Appendix 5 regarding dataset composition, QA accuracy calculations, and clinical evaluation criteria.
3. **Technical clarity:**

   - Clarified training details of AiMed model in Appendix 1, including data before-and-after comparisons.
   - Explained RAG implementation (Fig. 2), explicitly outlining the QA process.
   - Addressed clinical scenario diversity, acknowledging limitations, and suggesting future work directions in Discussion.
4. **Evaluation transparency:**

   - Clearly explained evaluation methodology and clinician evaluation procedures in Appendix 5.2.
   - Provided inter-rater agreement analysis among clinicians in Results.

### Reviewer 4

1. **Completeness and detail of results:**

   - Expanded Results with complete datasets, in-depth analysis, and comprehensive discussions.
2. **Framework representativeness and scope:**

   - Clarified the practical constraints for comprehensive scenario testing, noting our ongoing efforts to acquire more diverse data.
   - Explicitly stated rationale for initial scenario selections (QA and clinical diagnosis).
   - Expanded Discussion section to outline future expansion plans for scenario coverage.

### Reviewer 5

1. **Terminology and specificity of MedRad:**

   - Clearly defined "MedRad" acronym and specified focus in the Introduction.
2. **Language clarity and phrasing improvements:**

   - Revised phrasing for clarity as suggested (e.g., "In late 2022") throughout Introduction and Related Work sections.
3. **Clarification of computational complexity:**

   - Clearly explained "higher arithmetic consumption" in context of computational cost, explicitly detailed in Introduction.
4. **Clarifying research gaps:**

   - Strengthened articulation of MedRad's unique contributions and addressed research gaps clearly in Related Work section.
5. **Dataset source and preprocessing:**

   - Detailed data source and preprocessing steps comprehensively described in Methods (Medical Dataset section).
6. **Individual component contribution:**

   - Added ablation studies to clearly show each component's individual contribution in Results.
7. **Failure analysis:**

   - Included detailed discussion on common failure cases and underlying reasons in Results.
8. **Clinician feedback:**

   - Incorporated explicit clinician feedback regarding model interpretability and utility in Results.
9. **International applicability and multilingualism:**

   - Discussed feasibility, prospects, and challenges of international and multilingual deployment in Results.
10. **Regulatory and legal considerations:**

    - Addressed regulatory compliance, legal implications, and need for human oversight in clinical settings within Related Work and Discussion sections.

We sincerely appreciate the thoughtful suggestions and believe the revisions have significantly improved the clarity, robustness, and scholarly value of our manuscript. We look forward to your further consideration of our revised manuscript.

Warm regards,

[Authors' Names]
